name: Tourism Project Pipeline

on:
  push:
    branches:
      - main  # Trigger workflow on push to main

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install huggingface_hub

      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python - <<EOF
          import os
          from huggingface_hub import HfApi

          api = HfApi()
          repo_id = "absethi1894/MLOps"

          # Ensure repo exists
          try:
              api.repo_info(repo_id=repo_id)
          except:
              api.create_repo(repo_id=repo_id, repo_type="model", private=False)

          dataset_path = "data/tourism.csv"

          # Download dataset at runtime if missing
          if not os.path.isfile(dataset_path):
              import urllib.request
              url = "https://your-dataset-url.com/tourism.csv"  # Replace with real URL
              os.makedirs(os.path.dirname(dataset_path), exist_ok=True)
              urllib.request.urlretrieve(url, dataset_path)

          api.upload_file(
              path_or_fileobj=dataset_path,
              path_in_repo="data/tourism.csv",
              repo_id=repo_id,
              token=os.environ["HF_TOKEN"]
          )
          EOF

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Data Preparation
        run: python model_building/prep.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install mlflow huggingface_hub

      - name: Start MLflow Server
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 &
          sleep 5

      - name: Train Model
        run: python model_building/train.py

      - name: Upload Trained Model to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python - <<EOF
          import os
          from huggingface_hub import HfApi

          api = HfApi()
          repo_id = "absethi1894/MLOps"

          # Ensure repo exists
          try:
              api.repo_info(repo_id=repo_id)
          except:
              api.create_repo(repo_id=repo_id, repo_type="model", private=False)

          model_file = "artifacts/tourism_xgb_model.pkl"

          if os.path.isfile(model_file):
              api.upload_file(
                  path_or_fileobj=model_file,
                  path_in_repo="artifacts/tourism_xgb_model.pkl",
                  repo_id=repo_id,
                  token=os.environ["HF_TOKEN"]
              )
          else:
              print(f"Model file {model_file} not found!")
          EOF

  deploy-hosting:
    needs: [model-training, data-prep, register-dataset]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Push files to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"
          git add .
          git commit -m "Update from workflow" || echo "No changes to commit"
          git push https://huggingface:${{ secrets.HF_TOKEN }}@huggingface.co/spaces/absethi1894/MLOps main
