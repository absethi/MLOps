name: Tourism Project Pipeline

on:
  push:
    branches:
      - main

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install huggingface_hub

      - name: Upload raw dataset to HF Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python - <<EOF
          import os
          from huggingface_hub import HfApi, create_repo

          HF_TOKEN = os.environ["HF_TOKEN"]
          api = HfApi(token=HF_TOKEN)

          dataset_repo = "absethi1894/Visit_with_Us"
          try:
              api.repo_info(repo_id=dataset_repo, repo_type="dataset")
              print(f"Dataset repo '{dataset_repo}' exists.")
          except Exception:
              create_repo(repo_id=dataset_repo, repo_type="dataset", private=False)
              print(f"Dataset repo '{dataset_repo}' created.")

          dataset_path = "data/tourism.csv"
          if not os.path.isfile(dataset_path):
              import urllib.request
              os.makedirs(os.path.dirname(dataset_path), exist_ok=True)
              url = "https://raw.githubusercontent.com/absethi/MLOps/main/data/tourism.csv"
              urllib.request.urlretrieve(url, dataset_path)

          api.upload_file(
              path_or_fileobj=dataset_path,
              path_in_repo="data/tourism.csv",
              repo_id=dataset_repo,
              repo_type="dataset"
          )
          print("Raw dataset uploaded.")
          EOF

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install huggingface_hub scikit-learn pandas

      - name: Run Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python model_building/prep.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install mlflow xgboost scikit-learn pandas joblib huggingface_hub

      - name: Start MLflow Server
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 &
          sleep 5

      - name: Train Model
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python model_building/train.py
